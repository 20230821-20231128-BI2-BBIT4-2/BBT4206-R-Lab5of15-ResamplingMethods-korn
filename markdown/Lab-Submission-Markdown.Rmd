---
title: "Business Intelligence Project"
author: "korn"
date: "18/10/23"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

+---------------------------------------------------+---------------------------------------------+
| **Student ID Numbers and Names of Group Members** | 1.  134644 - C - Sebastian Muramara         |
|                                                   |                                             |
|                                                   | 2.  136675 - C - Bernard Otieno             |
|                                                   |                                             |
|                                                   | 3.  131589 - C - Agnes Anyango              |
|                                                   |                                             |
|                                                   | 4.  131582 - C - Njeri Njuguna              |
|                                                   |                                             |
|                                                   | 5.  136009 - C- Sera Ndabari                |
+---------------------------------------------------+---------------------------------------------+
| **GitHub Classroom Group Name**                   | Korn                                        |
+---------------------------------------------------+---------------------------------------------+
| **Course Code**                                   | BBT4206                                     |
+---------------------------------------------------+---------------------------------------------+
| **Course Name**                                   | Business Intelligence II                    |
+---------------------------------------------------+---------------------------------------------+
| **Program**                                       | Bachelor of Business Information Technology |
+---------------------------------------------------+---------------------------------------------+
| **Semester Duration**                             | 21^st^ August 2023 to 28^th^ November 2023  |
+---------------------------------------------------+---------------------------------------------+

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)
```
## LAB 5
## STEP 1. INSTALL PACKAGES
```{r packages}

if (require("languageserver")) {
  require("languageserver")
} else {
  install.packages("languageserver", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
## caret ----
if (require("caret")) {
  require("caret")
} else {
  install.packages("caret", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## klaR ----
if (require("klaR")) {
  require("klaR")
} else {
  install.packages("klaR", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## e1071 ----
if (require("e1071")) {
  require("e1071")
} else {
  install.packages("e1071", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## readr ----
if (require("readr")) {
  require("readr")
} else {
  install.packages("readr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## LiblineaR ----
if (require("LiblineaR")) {
  require("LiblineaR")
} else {
  install.packages("LiblineaR", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## naivebayes ----
if (require("naivebayes")) {
  require("naivebayes")
} else {
  install.packages("naivebayes", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
```
## STEP 2. LOAD THE DATASET
```{r Dataset}
if (require("mlbench")) {
  require("mlbench")
} else {
  install.packages("mlbench", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
if (require("caret")) {
  require("caret")
} else {
  install.packages("caret", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
##Install mlbench
##install.packages("mlbench")
##require("mlbench")
##require("caret")
data("PimaIndiansDiabetes")
summary("PimaIndiansDiabetes")


```
## STEP 3. DATA ANALYSIS
```{r DATA ANALYSIS}
##summary of each column in the dataset
  par(mfrow=c(1,4));
  for(i in 1:4){
    hist(PimaIndiansDiabetes[,i], main=names(PimaIndiansDiabetes)[i])
  }
  
  library(lattice)
  #create a layout of simpler density plots by attribute
  par(mfrow=c(1,4))
  for (i in 1:4) {
    plot(density(PimaIndiansDiabetes[,i]), main=names(PimaIndiansDiabetes)[i])}

  par(mfrow=c(1,4))
  for(i in 1:4) {
    boxplot(PimaIndiansDiabetes[,i], main=names(PimaIndiansDiabetes)[i])
  }  

  par(mfrow=c(1,4))
  for(i in 1:4){
    counts <- table(PimaIndiansDiabetes[,i])
    name <-names(PimaIndiansDiabetes)[i]
    barplot(counts,main=name)
  }  
```

## STEP 4. SPLIT THE DATASET
```{r Splitting}
  ##split the dataset
  train_index = sample(c(T, F), nrow(PimaIndiansDiabetes), prob = c(0.8, 0.2), replace = TRUE)
  train_data <- PimaIndiansDiabetes[train_index,]
  test_data <- PimaIndiansDiabetes[!train_index,]
```
## STEP 5. TRAINING AND TESTING
### Regression: Linear Mode
```{r Regression: Linear Mode}
  train_index <- createDataPartition(PimaIndiansDiabetes$`diabetes`, # nolint
                                     p = 0.80, list = FALSE)
  PimaIndians_dataset_train <- PimaIndiansDiabetes[train_index, ]
  PimaIndians_dataset_test <- PimaIndiansDiabetes[-train_index, ] 
  

  train_control <- trainControl(method = "boot", number = 500)
  
  fit <- glm(formula = diabetes ~ ., family = binomial, data = PimaIndians_dataset_train)
  
  test.predict = ifelse(predict(fit, test_data, type = "response") > 0.5, "Yes", "No")
  cm1 <- table(test.predict, test_data$diabetes)
  sum(diag(cm1)) / sum(cm1)
```
## 3. Classification: LDA with k-fold Cross Validation ----
### 3.a. LDA classifier based on a 5-fold cross validation ----
```{r LDA classifier based on a 5-fold cross validation }
train_control <- trainControl(method = "cv", number = 5)
  
  Pima_Indians_dateset_model_lda <-
    caret::train(diabetes ~ ., data = PimaIndians_dataset_train,
                 trControl = train_control, na.action = na.omit, method = "lda2",
                 metric = "Accuracy")
  
  ### 3.b. Test the trained LDA model using the testing dataset ----
  predictions_lda <- predict(Pima_Indians_dateset_model_lda,
                             PimaIndians_dataset_test[, 1:8])
  
  ### 3.c. View the summary of the model and view the confusion matrix ----
  print(Pima_Indians_dateset_model_lda)
  caret::confusionMatrix(predictions_lda, PimaIndians_dataset_test$diabetes)
```
## 4. Classification: Naive Bayes with Repeated k-fold Cross Validation ----
### 4.a. Train an e1071::naive Bayes classifier based on the churn variable ----
```{r Naive Bayes with Repeated k-fold Cross Validation}
Pima_Indians_dateset_model_nb <-
    e1071::naiveBayes(`diabetes` ~ ., data = PimaIndians_dataset_train)
  
  ### 4.b. Test the trained naive Bayes classifier using the testing dataset ----
  Pima_Indians_predictions_nb_e1071 <-
    predict(Pima_Indians_dateset_model_nb, PimaIndians_dataset_test[, 1:8])
  
  
  ### 4.c. View a summary of the naive Bayes model and the confusion matrix ----
  print(Pima_Indians_dateset_model_nb)
  caret::confusionMatrix(Pima_Indians_predictions_nb_e1071, PimaIndians_dataset_test$diabetes)
  
```
 
## 5. Classification: SVM with Repeated k-fold Cross Validation ----
### 5.a. SVM Classifier using 5-fold cross validation with 3 reps ----

```{r SVM with Repeated k-fold Cross Validation}

  
  train_control <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
  
  Pima_Indians_model_svm <-
    caret::train(`diabetes` ~ ., data = PimaIndians_dataset_train,
                 trControl = train_control, na.action = na.omit,
                 method = "svmLinearWeights2", metric = "Accuracy")
  
  ### 5.b. Test the trained SVM model using the testing dataset ----
  predictions_svm <- predict(Pima_Indians_model_svm, PimaIndians_dataset_test[, 1:8])
  
  ### 5.c. View a summary of the model and view the confusion matrix ----
  print(Pima_Indians_model_svm)
  caret::confusionMatrix(predictions_svm, PimaIndians_dataset_test$diabetes)
```
## 6. Classification: Naive Bayes with Leave One Out Cross Validation ----
```{r Naive Bayes with Leave One Out Cross Validation}
  ### 6.a. Train a Naive Bayes classifier based on an LOOCV ----
  train_control <- trainControl(method = "LOOCV")
  
  Pima_Indians_dateset_model_nb_loocv <-
    caret::train(`diabetes` ~ ., data = PimaIndians_dataset_train,
                 trControl = train_control, na.action = na.omit,
                 method = "naive_bayes", metric = "Accuracy")
  
  ### 6.b. Test the trained model using the testing dataset ====
  predictions_nb_loocv <-
    predict(Pima_Indians_dateset_model_nb_loocv, PimaIndians_dataset_test[, 1:8])
  
  ### 6.c. View the confusion matrix ====
  print(Pima_Indians_dateset_model_nb_loocv)
  caret::confusionMatrix(predictions_nb_loocv, PimaIndians_dataset_test$diabetes)
```

